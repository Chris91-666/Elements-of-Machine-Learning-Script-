

\chapter{Hash Functions}

\textbf{Fingerprinting}
\begin{itemize}
    \item Problem: You have a large file/object and want to compare to objects in a database
    \item E.g. check if you object is in the database
    \item Object too large to send to the server
    \item $\Rightarrow$ Need a small unique identifier/digest of your object
    \item \textbf{Hashing!}
    \item Compress objects into a small fingerprint
    \item $\Rightarrow$ Speed up comparisons/membership tests, smaller communication cost\newline
\end{itemize}


\begin{definition}[Hash Functions]\ \\
    \textbf{Syntax:}
    A family of hash functions is given by a pair of algorithms $(Gen,H)$
    \begin{itemize}
        \item $Gen(1^{\lambda})$: A probabilistic algorithm which on input $1^{\lambda}$ outputs a key $S$
        \item $H^S(x)$: A deterministic algorithm which on input a key $S$ and a string $x \in \{o,1\}^*$ outputs a hash value $h \in \{0,1\}^l$
    \end{itemize}
    \textbf{Remarks:}
    \begin{itemize}
        \item The output length $l=l(\lambda)$ only depends on $\lambda$
        \item If $H^S$ is only defined on inputs of length $l' > l$ we call $H$ a fixed-length hash function
        \item If we don't specify $Gen$ it just chooses uniformly random $s \leftarrow_{\$} \{0,1\}^{\lambda}$\newline
    \end{itemize}
\end{definition}


\begin{definition}[Collision Resistance]\ \\
    A hash function $(Gen,H)$ is called collision-resistant, if for every PPT-bounded adversary $\mathcal{A}$ there exists a negligible function $v$ s.t. for all $\lambda \in \mathbb{N}$
    $$Pr[Hash-Col_{\mathcal{A}}(\lambda)=1] < v(\lambda)$$
\end{definition}


\textbf{Idealized Hash Functions}
\begin{itemize}
    \item Sometimes collision resistance isn’t enough…
    \item Sometimes we need hash functions for which it is hard to find arbitrary correlations
    \item E.g. for a fixed function $f$ it should be hard to find an input $x$ with $H^S(x)=f(x)$
    \item How should an ideal hash function behave?
    \item Like a random function!\newline
\end{itemize}


\textbf{The random oracle model}
\begin{itemize}
    \item Random Oracle (RO): Uniformly random function $\mathcal{H}: \{0,1\}^l \to \{0,1\}^{\lambda}$ which can only be accessed via oracle access/blackbox access
    \item Random oracle is uniform on positions it has not been queried on
    \item Models a hash function whose code no-one knows
    \item Rationale: The only way of learning something about a hash function which is modeled by RO is to evaluate it
    \item To evaluate $\mathcal{H}$ adversary needs to provide input explicitly to random oracle
    \item Idea: In security proofs reduction controls RO!\newline
\end{itemize}


\textbf{The Random Oracle Model}
\begin{itemize}
    \item Obviously, real hash functions are not random oracles
    \item E.g. real hash functions have small description (e.g. program)
    \item Sometimes, we only know how to prove constructions secure if $\mathcal{H}$ is modeled as random oracle
    \item Two step approach:
    \begin{itemize}
        \item Model hash function as a RO in the security proof
        \item In the real world, instantiate with actual hash function
    \end{itemize}
    \item Better than no proof at all!
    \item Proofs in RO model are heuristic
    \item If a scheme is secure in the RO model, but insecure in real world, adversary must do something non trivial and interesting with hash function\newline
\end{itemize}


\begin{definition}[Security Definition]\ \\
    \textbf{The collision-finding experiment} $Hash-coll_{\mathcal{A},(Gen,H)}(n)$
    \begin{itemize}
        \item On input $s$, $\mathcal{A}$ outputs $x$ and $x'$.
        \item $Hash-coll_{\mathcal{A},??? (05-02,3)}(n) = 
        \begin{cases} 
        1 & x \neq x' $ and $ H^S(x)=H^S(x')\\
        0 & otherwise
        \end{cases}$
    \end{itemize}
    In the above experiment,
    \begin{itemize}
        \item $\mathcal{A}$ is polynomial time bounded;
        \item if no efficient adversary can find a collision except with negligible probability, then $(Gen;H)$ is collision resistant.
    \end{itemize}
    Some weaker security notions are also considered:
    \begin{itemize}
        \item second-preimage resistance: given $s$ and a random $x$, it is infeasible for a probabilistic polynomial-time adversary to find $x' \neq x$ such that $H^S(x') = H^S(x)$.
        \item preimage resistance: given $s$ and $a$ the hash $y = H^S(x_0)$ of a random $x_0$, it is infeasible for a probabilistic polynomial-time adversary to find $x$ such that $H^S(x) = y$.\newline
    \end{itemize}
\end{definition}

\newpage

\textbf{A word on Provable Security}
\begin{itemize}
    \item Hash functions in the real world are generally unkeyed and have a fixed output length.
    \item Problematic from a theoretical standpoint.
    \item Current hash functions are still collision resistant since no colliding pair is known, and would be computationally difficult to find.
    \item A hash function with output length n is considered secure as long as:
    \begin{itemize}
        \item no known algorithm can find a colliding pair in time much smaller than $2^{n/2}$;
        \item no known algorithm can find a preimage or second preimage in time much smaller than $2^n$.
    \end{itemize}
    \item Provable security for hash functions follows the same patterns as provable security for block ciphers.\newline
\end{itemize}


\begin{definition}[The Merkle-Dåmgard construction]\ 
    \begin{itemize}
        \item $(Gen,f)$ is a fixed-length hash function for inputs of length $2n$ and outputs of length $n$.
        \item $(Gen,F)$ (as defined above) operates on strings of length $L < 2^n$.
        \item To compute $pad(M)$: pad the message $M$ with 0 until its length is a multiple of $n$, then add a final block that corresponds to $L$ encoded as an $n$-bit string.
        \item IV is called the initialization vector, and is an arbitrary constant.\newline
    \end{itemize}
\end{definition}


\begin{theorem}
    If $(Gen,f)$ is collision resistant, so is $(Gen,F)$.\newline
\end{theorem}


\textbf{The Design of Compression Functions}\newline
General structure of the compression functions that we are going to deal with in the examples:
\begin{itemize}
    \item The function operates over $w$-bit words.
    \item Its input is divided in two parts: a state, which stores the output of the previous call to the compression function, and a block of $n_c$ words of padded data.
    \item Compression functions are generally iterative: a simple round is repeated $r$ times.
    \item A linear function extends the $n_c$ words of data into $r$ words of extended data.
    \item At each round, the state is updated with a nonlinear function, and a round constant and a word of extended data are absorbed in the state.\newline
\end{itemize}


\begin{definition}[Sponge Functions]\ 
    \begin{itemize}
        \item Generic structure to build a hash function from a public and unkeyed function $f$.
        \item $f$ is usually a permutation.
        \item The $b$-bit function is repeatedly applied to a state consisting in:
        \begin{itemize}
            \item a $r$-bit outer state, where $r$ is called the rate;
            \item a $c$-bit inner state, where $c=b-r$ s called the capacity.
        \end{itemize}
        \item Padding of a message can be done by appending a single bit 1, followed by bits 0 until the length of the result is a multiple of $r$.\newline
    \end{itemize}
\end{definition}


\textbf{A word on Provable Security}\ \\
How to justify the soundness of the sponge construction?
\begin{itemize}
    \item The function $f$ is fixed and public. To study the structure, we model it as a uniformly random function (or permutation). The resulting construction is called a random sponge.
    \item How close is the random sponge from a random oracle?
\end{itemize}

\begin{definition}
    Let $D$ be a probabilistic algorithm that deals at most $q$ oracle queries. Its distinguishing advantage is defined as
    $$\mathcal{A}_{Sponge}^{dist}(D) \coloneq \vert Pr[D^{Sponge[f](\cdot)}=1]-Pr[D^{H(\cdot)}=1] \vert,$$
    where the first probability is taken over the uniformly random draw of $f: \{0,1\}^b \to \{0,1\}^b$ and the second one over the uniformly random draw of the function $H$.
\end{definition}

\begin{itemize}
    \item However, for a concrete hash function, $f$ is public!
    \item An adversary has access to any intermediate value.
    \item Hence, we have to give access to $f$ when the adversary is interacting with $Sponge[f]$.
    \item In the random function case, a simulator is defined. It is a probabilistic polynomial time algorithm with access to the random oracle, whose goal is mimic the internal function of a random sponge.
\end{itemize}

\begin{definition}
    Let $D$ be a probabilistic algorithm that deals at most $q$ oracle queries. Its differentiating advantage is defined as
    $$\mathcal{A}_{Sponge}^{diff,S}(D) \coloneq \vert Pr[D^{Sponge[f](\cdot),f(\cdot)}=1]-Pr[D^{H(\cdot),S[H](\cdot)}=1] \vert,$$
    where the first probability is taken over the uniformly random draw of $f: \{0,1\}^b \to \{0,1\}^b$ and the second one over the uniformly random draw of the function $H$.
\end{definition}

\begin{theorem}\label{thPS}
There exists a simulator $S$ such that, for every a probabilistic algorithm $D$ whose queries require at most $q < 2^c$ calls to $f$, one has
$$\mathcal{A}_{Sponge}^{diff,S}(d) \leq 1 - \prod\limits_{i=1}^q (1 - \frac{i}{2^c}) \lessapprox \frac{q(q+1)}{2^{c+1}}$$
\end{theorem}

Interpretation of theorem \ref{thPS}:
\begin{itemize}
    \item It does not provide actual security guaranties for any concrete hash functions.
    \item But it does justify the soundness of the structure.
    \item It also provides a lower bound on the capacity: $c \geq 2n$, where $n$ is the output length.\newline
\end{itemize}

